{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949679a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laptop\\AppData\\Local\\Temp\\ipykernel_21772\\4238002918.py:311: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Multi-Class training on cuda for 40 epochs with 7 classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 (Train):   0%|          | 0/713 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, jaccard_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# NOTE: Geoprocessing libraries are kept but will only be useful if specific classes are vectorized.\n",
    "import rasterio.features\n",
    "from shapely.geometry import shape\n",
    "\n",
    "# Import utilities from the other files\n",
    "from data_utils_7 import SegmentationDataset, enhance_image_dip\n",
    "# IMPORTANT: get_model, combined_loss, and iou_score MUST be updated in model_utils.py \n",
    "# to handle the 7-class multi-class segmentation task.\n",
    "from model_utils_7 import get_model, combined_loss, iou_score # Assuming these are updated\n",
    "\n",
    "# --- Configuration ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 10\n",
    "NUM_EPOCHS = 40\n",
    "LR = 1e-4\n",
    "IMAGE_SIZE = 128 # Define image size for consistency\n",
    "NUM_CLASSES = 7  # <--- CRITICAL CHANGE: Now 7 classes\n",
    "\n",
    "# Class Names for visualization (0 is typically background/unlabelled if not explicitly used)\n",
    "CLASS_NAMES = [\n",
    "    'Informal Settlements', 'Built-Up', 'Impervious Surfaces', \n",
    "    'Vegetation', 'Barren', 'Water', 'Unlabelled (Class 7)'\n",
    "]\n",
    "# NOTE: The provided list has 7 names, starting from 1. \n",
    "# In multi-class segmentation, the 0-th index is often used, so we'll map the labels 0-6.\n",
    "# If your masks are 1-7, you MUST map them to 0-6 in SegmentationDataset.\n",
    "\n",
    "# --- Data Path Placeholders ---\n",
    "BASE_PATH = \"../../Dataset/Dataset/Prepared_Dataset\"\n",
    "TRAIN_IMG_DIR = os.path.join(BASE_PATH, \"train/images\")\n",
    "TRAIN_MASK_DIR = os.path.join(BASE_PATH, \"train/masks\")\n",
    "VAL_IMG_DIR = os.path.join(BASE_PATH, \"val/images\")\n",
    "VAL_MASK_DIR = os.path.join(BASE_PATH, \"val/masks\")\n",
    "\n",
    "\n",
    "# --- Augmentations ---\n",
    "train_transform = A.Compose([\n",
    "    A.RandomRotate90(),\n",
    "    A.HorizontalFlip(),\n",
    "    A.VerticalFlip(),\n",
    "    A.Affine(rotate=(-15,15), scale=(0.9,1.1), translate_percent=(0.06,0.06)),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# --- Evaluation Function (Modified for Multi-Class) ---\n",
    "def validate_epoch(model, val_loader):\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_miou_sum = 0.0 # This is now Multi-Class mIoU\n",
    "    all_preds = []\n",
    "    all_masks = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in val_loader:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            # CRITICAL: Multi-Class masks are typically [B, H, W] with long (integer) labels\n",
    "            # The original code was: masks.to(DEVICE).squeeze(3).unsqueeze(1) for binary [B, 1, H, W]\n",
    "            # Now we assume SegmentationDataset loads masks as [H, W, 1] and ToTensorV2 makes it [1, H, W].\n",
    "            masks = masks.to(DEVICE).squeeze(-1).long() # Should be [B, H, W] and type long/int64\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(imgs) # Logits [B, NUM_CLASSES, H, W]\n",
    "                loss = combined_loss(logits, masks) # Loss function must use LongTensor for masks\n",
    "            \n",
    "            val_loss_sum += loss.item() * imgs.size(0)\n",
    "            \n",
    "            # CRITICAL: Multi-class prediction is argmax over the class dimension\n",
    "            preds = torch.argmax(logits, dim=1) # [B, H, W]\n",
    "\n",
    "            # The iou_score function must also be updated to calculate multi-class mIoU\n",
    "            val_miou_sum += iou_score(logits, masks, num_classes=NUM_CLASSES) * imgs.size(0)\n",
    "            \n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_masks.append(masks.cpu().numpy())\n",
    "\n",
    "    avg_loss = val_loss_sum / len(val_loader.dataset)\n",
    "    avg_miou = val_miou_sum / len(val_loader.dataset)\n",
    "    \n",
    "    # Concatenate all predictions and masks\n",
    "    all_preds = np.concatenate(all_preds, axis=0) # Shape [N, H, W]\n",
    "    all_masks = np.concatenate(all_masks, axis=0) # Shape [N, H, W]\n",
    "    \n",
    "    return avg_loss, avg_miou, all_preds, all_masks\n",
    "\n",
    "\n",
    "# --- DIP Post-Processing and Vectorization (Now highly specialized for single class) ---\n",
    "# NOTE: These functions are left here but are ONLY useful for *binary* extraction of one class (e.g., Built-Up).\n",
    "# To vectorize a specific class, you would need to extract that class's pixels (e.g., class 2) \n",
    "# from the multi-class mask and then use these functions.\n",
    "\n",
    "def post_process_mask_dip(raw_prediction_mask, min_area_threshold=50):\n",
    "    \"\"\"\n",
    "    Applies morphological closing and small object removal to a specific binary mask.\n",
    "    \"\"\"\n",
    "    # ... (Implementation kept the same as it operates on a single channel binary mask) ...\n",
    "    if raw_prediction_mask.max() <= 1:\n",
    "        raw_prediction_mask = raw_prediction_mask * 255\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "    closed_mask = cv2.morphologyEx(raw_prediction_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closed_mask, 4, cv2.CV_32S)\n",
    "    final_mask = np.zeros_like(closed_mask)\n",
    "\n",
    "    for i in range(1, num_labels):\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        if area >= min_area_threshold:\n",
    "            final_mask[labels == i] = 255\n",
    "\n",
    "    return final_mask.astype(np.uint8)\n",
    "\n",
    "\n",
    "def mask_to_polygons(final_mask, transform=None):\n",
    "    \"\"\"\n",
    "    Converts a single-class (binary) cleaned raster mask into Shapely vector polygons.\n",
    "    \"\"\"\n",
    "    # ... (Implementation kept the same) ...\n",
    "    polygons = []\n",
    "    # Assumes the single class to vectorize has value 1\n",
    "    for geom, value in rasterio.features.shapes(final_mask.astype(np.int16), mask=final_mask, transform=transform):\n",
    "        if value > 0:\n",
    "            polygons.append(shape(geom))\n",
    "    return polygons\n",
    "\n",
    "\n",
    "# --- Sliding Window Inference Sketch (Now Multi-Class) ---\n",
    "def sliding_window_predict(large_image_path, model, tile_size=120, overlap_ratio=0.5):\n",
    "    \"\"\"\n",
    "    NOTE: In the full multi-class implementation, full_logit_map would be [H, W, NUM_CLASSES].\n",
    "    This sketch is still heavily simplified.\n",
    "    \"\"\"\n",
    "    print(\"--- Running Multi-Class Sliding Window Inference Sketch (Simplified) ---\")\n",
    "\n",
    "    img = cv2.imread(large_image_path)\n",
    "    # H, W, _ = img.shape\n",
    "    \n",
    "    # 1. Simulate the multi-class result: a final predicted mask [H, W] with integer class labels\n",
    "    # Simulating a result:\n",
    "    H, W = 600, 600 \n",
    "    full_pred_mask = np.random.randint(0, NUM_CLASSES, size=(H, W), dtype=np.uint8) \n",
    "\n",
    "    # 2. To get a single-class vectorization (e.g., for 'Built-Up', which is class 2, index 1)\n",
    "    target_class_index = 1 \n",
    "    # Create a binary mask for JUST the target class\n",
    "    raw_binary_mask_for_vectorization = (full_pred_mask == target_class_index).astype(np.uint8) * 255\n",
    "    \n",
    "    # 3. DIP Post-Processing on the chosen class\n",
    "    cleaned_mask_for_target_class = post_process_mask_dip(raw_binary_mask_for_vectorization)\n",
    "    \n",
    "    # 4. Vectorization\n",
    "    polygons = mask_to_polygons(cleaned_mask_for_target_class, transform=None) \n",
    "\n",
    "    print(f\"Inference complete. Total {CLASS_NAMES[target_class_index]} polygons found: {len(polygons)}\")\n",
    "    return full_pred_mask, polygons # Return the full mask and the specific polygons\n",
    "\n",
    "\n",
    "# --- NEW: Plotting Function (Updated for Multi-Class) ---\n",
    "def plot_results(\n",
    "    train_losses, val_losses, val_mious,\n",
    "    all_val_preds, all_val_masks,\n",
    "    val_dataset,\n",
    "    num_sample_images=5,\n",
    "    class_names=CLASS_NAMES\n",
    "):\n",
    "    print(\"\\n--- Generating Visualizations (Multi-Class) ---\")\n",
    "    \n",
    "    # ... (Training & Validation Loss/Metrics Graphs remain the same) ...\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training & Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_mious, label='Validation mIoU', color='orange')\n",
    "    plt.title('Validation Mean IoU (mIoU) - Multi-Class')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('mIoU')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"Generated: Training and Validation Curves\")\n",
    "    \n",
    "    # --- 2. Confusion Matrix (Multi-Class) ---\n",
    "    # Flatten the masks and predictions for confusion matrix calculation\n",
    "    # all_val_masks and all_val_preds are [N, H, W], so flatten to [N*H*W]\n",
    "    flat_true = all_val_masks.flatten()\n",
    "    flat_pred = all_val_preds.flatten()\n",
    "    \n",
    "    cm = confusion_matrix(flat_true, flat_pred, labels=np.arange(NUM_CLASSES))\n",
    "    \n",
    "    plt.figure(figsize=(10, 8)) # Increased size for 7 classes\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False,\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Pixel-wise Confusion Matrix (Multi-Class)')\n",
    "    plt.show()\n",
    "    print(\"Generated: Confusion Matrix\")\n",
    "\n",
    "    # --- 3. Quantitative Metrics Summary (Table) ---\n",
    "    overall_accuracy = accuracy_score(flat_true, flat_pred)\n",
    "    # For Multi-Class, use 'macro' or 'weighted' for mIoU/F1\n",
    "    overall_miou_macro = jaccard_score(flat_true, flat_pred, average='macro', zero_division=0) \n",
    "    f1_macro = f1_score(flat_true, flat_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    print(\"\\n--- Quantitative Metrics Summary (on Validation Set) ---\")\n",
    "    print(f\"Overall Pixel Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Mean IoU (Jaccard Index) [Macro]: {overall_miou_macro:.4f}\")\n",
    "    print(f\"F1-Score [Macro]: {f1_macro:.4f}\")\n",
    "\n",
    "    # You can also use precision_score, recall_score with average='None' to get per-class metrics\n",
    "    precision_per_class = precision_score(flat_true, flat_pred, average=None, labels=np.arange(NUM_CLASSES), zero_division=0)\n",
    "    recall_per_class = recall_score(flat_true, flat_pred, average=None, labels=np.arange(NUM_CLASSES), zero_division=0)\n",
    "    \n",
    "    print(\"\\n--- Per-Class Metrics ---\")\n",
    "    print(f\"{'Class':<20} | {'Precision':<10} | {'Recall':<10}\")\n",
    "    print(\"-\" * 45)\n",
    "    for i in range(NUM_CLASSES):\n",
    "        print(f\"{class_names[i]:<20} | {precision_per_class[i]:<10.4f} | {recall_per_class[i]:<10.4f}\")\n",
    "\n",
    "\n",
    "    # --- 4. Visual Examples of Segmentation ---\n",
    "    # NOTE: You'll need a color map to visualize multi-class masks, as grayscale won't be enough.\n",
    "    cmap = plt.cm.get_cmap('viridis', NUM_CLASSES) \n",
    "    plt.figure(figsize=(15, num_sample_images * 4)) \n",
    "    sample_indices = np.random.choice(len(val_dataset), num_sample_images, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        original_img_tensor, true_mask_tensor = val_dataset[idx]\n",
    "        \n",
    "        # Denormalize image for display\n",
    "        img_display = original_img_tensor.permute(1, 2, 0).numpy() # CHW to HWC\n",
    "        mean = np.array([0.485,0.456,0.406])\n",
    "        std = np.array([0.229,0.224,0.225])\n",
    "        img_display = std * img_display + mean\n",
    "        img_display = np.clip(img_display, 0, 1)\n",
    "\n",
    "        true_mask_display = true_mask_tensor.squeeze().numpy() # [H, W]\n",
    "        predicted_mask_display = all_val_preds[idx].squeeze()  # [H, W]\n",
    "\n",
    "        plt.subplot(num_sample_images, 3, i * 3 + 1)\n",
    "        plt.imshow(img_display)\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(num_sample_images, 3, i * 3 + 2)\n",
    "        plt.imshow(true_mask_display, cmap=cmap, vmin=0, vmax=NUM_CLASSES-1)\n",
    "        plt.title('Ground Truth Mask')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(num_sample_images, 3, i * 3 + 3)\n",
    "        plt.imshow(predicted_mask_display, cmap=cmap, vmin=0, vmax=NUM_CLASSES-1)\n",
    "        plt.title('Predicted Mask')\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(f\"Generated: {num_sample_images} Visual Segmentation Examples\")\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "def main():\n",
    "    if not os.path.exists(TRAIN_IMG_DIR) or not os.path.exists(VAL_IMG_DIR):\n",
    "        print(\"!! ERROR: Please ensure data paths are correct and the dataset is downloaded/extracted.\")\n",
    "        print(f\"Expected path: {BASE_PATH}\")\n",
    "        return \n",
    "\n",
    "    # 1. DataLoaders\n",
    "    train_dataset = SegmentationDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, transform=train_transform)\n",
    "    val_dataset = SegmentationDataset(VAL_IMG_DIR, VAL_MASK_DIR, transform=val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    # 2. Model, Optimizer, Scheduler\n",
    "    # CRITICAL: get_model(NUM_CLASSES) should be called if it takes the number of classes as an argument.\n",
    "    # Assuming get_model has been updated to use NUM_CLASSES=7.\n",
    "    model = get_model(DEVICE) \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5, mode='max')\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    best_miou = 0.0\n",
    "    \n",
    "    train_losses_history = []\n",
    "    val_losses_history = []\n",
    "    val_mious_history = []\n",
    "    \n",
    "    final_val_preds = None\n",
    "    final_val_masks = None\n",
    "\n",
    "    # 3. Training Loop\n",
    "    print(f\"Starting Multi-Class training on {DEVICE} for {NUM_EPOCHS} epochs with {NUM_CLASSES} classes...\")\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # Training\n",
    "        for batch_idx, (imgs, masks) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS} (Train)\")):\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            # CRITICAL: Mask handling changed for multi-class [B, H, W]\n",
    "            masks = masks.to(DEVICE).squeeze(-1).long() # [B, H, W] of type torch.long\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(imgs) # [B, 7, H, W]\n",
    "                loss = combined_loss(logits, masks) # Must use multi-class loss\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_losses_history.append(avg_train_loss) \n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_miou, current_epoch_preds, current_epoch_masks = validate_epoch(model, val_loader)\n",
    "        val_losses_history.append(val_loss) \n",
    "        val_mious_history.append(val_miou)  \n",
    "        \n",
    "        # Store predictions and masks from the LAST epoch for final confusion matrix/metrics\n",
    "        final_val_preds = current_epoch_preds\n",
    "        final_val_masks = current_epoch_masks\n",
    "\n",
    "        scheduler.step(val_miou)\n",
    "\n",
    "        print(f\"Epoch {epoch} finished. Train Loss: {avg_train_loss:.4f} | Val Loss: {val_loss:.4f} | Val mIoU: {val_miou:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_miou > best_miou:\n",
    "            best_miou = val_miou\n",
    "            torch.save(model.state_dict(), \"best_model_10.pth\")\n",
    "            print(\"Model saved!\")\n",
    "            # Save predictions from the best model epoch\n",
    "            final_val_preds = current_epoch_preds\n",
    "            final_val_masks = current_epoch_masks\n",
    "\n",
    "\n",
    "    # 4. Generate and Plot Results\n",
    "    # Load the best model weights if the last epoch was not the best\n",
    "    if not os.path.exists(\"best_model_50.pth\"):\n",
    "        print(\"Warning: best_model_10.pth not found. Using last epoch model state.\")\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(\"best_model_10.pth\"))\n",
    "        # Re-run evaluation on the best model to ensure final_val_preds/masks are correct\n",
    "        _, _, final_val_preds, final_val_masks = validate_epoch(model, val_loader)\n",
    "\n",
    "\n",
    "    plot_results(\n",
    "        train_losses_history,\n",
    "        val_losses_history,\n",
    "        val_mious_history,\n",
    "        final_val_preds,\n",
    "        final_val_masks,\n",
    "        val_dataset,\n",
    "        num_sample_images=5 \n",
    "    )\n",
    "            \n",
    "    # 5. Optional: Inference and Post-processing (using the best model)\n",
    "    # print(\"\\n--- Starting Optional Multi-Class Inference and Post-processing Sketch ---\")\n",
    "    # SAMPLE_LARGE_IMAGE_PATH = \"path/to/your/full_patch_test_image.png\"\n",
    "    # if os.path.exists(SAMPLE_LARGE_IMAGE_PATH):\n",
    "    #     # The result here is the full multi-class prediction mask and polygons for a single class (Built-Up)\n",
    "    #     full_pred_mask, polygons = sliding_window_predict(SAMPLE_LARGE_IMAGE_PATH, model)\n",
    "    # else:\n",
    "    #     print(f\"Warning: Could not run full inference. Image path not found: {SAMPLE_LARGE_IMAGE_PATH}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        main()\n",
    "    except AssertionError as e:\n",
    "        print(f\"Fatal Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}. Check if model_utils.py functions (get_model, combined_loss, iou_score) support NUM_CLASSES=7 multi-class segmentation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
